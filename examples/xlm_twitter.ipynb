{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaFuLiya3sDc"
   },
   "source": [
    "# Building a topic/facet model using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niveHf59oPT4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import umap.plot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"/home/romain/projects/socsemics\"\n",
    "sys.path.append(PROJECT_PATH)\n",
    "\n",
    "from experiments.scripts.topic_modelling.st_tm.st_tm import STTopicModel\n",
    "import experiments.scripts.topic_modelling.st_tm.helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.join(PROJECT_PATH, \"experiments\", \"models\")\n",
    "TM_DIR = os.path.join(MODELS_DIR, \"topic_modelling\", \"st_tm\")\n",
    "DATA_DIR = os.path.join(PROJECT_PATH, \"experiments\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dFvUghb3o78"
   },
   "source": [
    "## Import and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlU0g6mgJvVt"
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"نوال الزغبي (الشاب خالد ليس عالمي) هههههههه أتفرجي على ها الفيديو يا مبتدئة http vía @user\",\n",
    "    \"Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman \",\n",
    "    \"\"\"Royal: le président n'aime pas les pauvres? \"c'est n'importe quoi\" http …\"\"\",\n",
    "    \"@user korrekt! Verstehe sowas nicht...\",\n",
    "    \"CONGRESS na ye party kabhi bani hoti na india ka partition hota nd na hi humari country itni khokhli hoti   @ \",\n",
    "    \"@user @user Ma Ferrero? il compagno Ferrero? ma il suo partito esiste ancora? allora stiamo proprio frecati !!!\",\n",
    "    \"todos os meus favoritos na prova de eliminação #MasterChefBR\",\n",
    "    \"@user jajajaja dale, hacete la boluda vos jajaja igual a vos nunca se te puede tomar en serio te mando un abrazo desde Perú!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
    "\n",
    "model = STTopicModel(embedding_model=MODEL_NAME,\n",
    "                     documents=docs,\n",
    "                     document_ids=None,\n",
    "                     verbose=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ = model.embed_corpus(pooling_method=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train topic/facet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.topic_extraction(n_components=5,\n",
    "                           n_neighbors=50,\n",
    "                           min_topic_size=500,\n",
    "                           min_samples=15,\n",
    "                           n_words=30,\n",
    "                           random_state=RANDOM_STATE,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.facet_extraction(n_components=5,\n",
    "                           n_neighbors=15,\n",
    "                           min_facet_size=10,\n",
    "                           min_samples=10,\n",
    "                           n_words=30,\n",
    "                           random_state=RANDOM_STATE,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, sizes = np.unique(model.doc_topic, return_counts=True)\n",
    "print(f\"Number of topics  : {len(topics)}\")\n",
    "print()\n",
    "print(f\"Sizes : {' '.join([str(s) for s in sizes])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = model.topic_extraction_parameters[\"n_neighbors\"]\n",
    "UMAP_2D_NAME = f\"umap_2d_{N_NEIGHBORS}_neighbors\"\n",
    "PATH_UMAP_2D = os.path.join(TM_DIR, UMAP_2D_NAME)\n",
    "\n",
    "if os.path.exists(PATH_UMAP_2D):\n",
    "    umap_model_2d = joblib.load(PATH_UMAP_2D)\n",
    "else:\n",
    "    umap_model_2d = umap.UMAP(n_neighbors=N_NEIGHBORS,\n",
    "                              n_components=2,\n",
    "                              min_dist=0,\n",
    "                              metric='cosine',\n",
    "                              low_memory=True,\n",
    "                              random_state=RANDOM_STATE).fit(model.document_vectors)\n",
    "    joblib.dump(umap_model_2d, PATH_UMAP_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_subset = None\n",
    "# topics_subset = [1, 9, 27, 43]\n",
    "\n",
    "axs = helpers.plot_topics(model, topics_subset=topics_subset, mark_noisy=False, \n",
    "                          umap_model_2d=umap_model_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, words in enumerate(model.topic_words):\n",
    "    print(f\"Topic {topic} : {' '.join(words)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore a particular topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 1\n",
    "\n",
    "docs, sims, docs_ids = helpers.get_topic_docs(model, topic)\n",
    "t_words_str = \" \".join(model.topic_words[topic][:10])\n",
    "\n",
    "print(f\"Topic {topic} : {t_words_str}\")\n",
    "print()\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"{doc} (sim={sims[i]:.2f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method == \"tv\" : embedding space topic vectors\n",
    "# method == \"tf_idf\" : tf-idf topic vectors\n",
    "top_top_sims = helpers.most_similar_topics(model, method=\"tv\")\n",
    "\n",
    "for top1, top2, sim in top_top_sims:\n",
    "    print(f\"Topic {top1} : {' '.join(model.topic_words[top1][:10])}\")\n",
    "    print(f\"Topic {top2} : {' '.join(model.topic_words[top2][:10])}\")\n",
    "    print(f\"sim : {sim:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facet exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterization of a topic's facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 2\n",
    "t_words_str = \" \".join(model.topic_words[topic][:10])\n",
    "\n",
    "print(f\"Topic {topic} : {t_words_str}\")\n",
    "print()\n",
    "\n",
    "for facet in model.topic_facets[topic].keys():\n",
    "    f_words_str = \" \".join(model.topic_facets[topic][facet][\"words\"][:10])\n",
    "    size = model.topic_facets[topic][facet][\"size\"]\n",
    "    f_rep_claim = helpers.get_topic_docs(model, topic, facet)[0][0]\n",
    "    print(f\"Facet {facet} ({size} docs) : {f_words_str}\")\n",
    "    print(f\"Representative claim : {f_rep_claim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore a particular facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 1\n",
    "facet = 33\n",
    "\n",
    "docs, sims, docs_ids = helpers.get_topic_docs(model, topic, facet)\n",
    "t_words_str = \" \".join(model.topic_words[topic][:10])\n",
    "f_size = model.topic_facets[topic][facet][\"size\"]\n",
    "f_words_str = \" \".join(model.topic_facets[topic][facet][\"words\"][:10])\n",
    "\n",
    "print(f\"Topic {topic} : {t_words_str}\")\n",
    "print(f\"Facet {facet} ({f_size} docs) : {f_words_str}\")\n",
    "print()\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"{doc} (sim={sims[i]:.2f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of a topic's facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers = reload(helpers)\n",
    "axs = helpers.plot_facets(model, topic=25, mark_noisy=False, interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of facets per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_facets_per_topic = np.array([len(model.topic_facets[t].keys()) for t in topics])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(topics, n_facets_per_topic)\n",
    "ax.tick_params(axis='x', colors='white', labelsize=15)\n",
    "ax.tick_params(axis='y', colors='white', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_few_facets = np.where(n_facets_per_topic < 10)[0]\n",
    "\n",
    "for topic in topics_few_facets:\n",
    "    print(f\"Topic {topic} : {' '.join(model.topic_words[topic])}\")\n",
    "    print()\n",
    "    \n",
    "labels = np.array([c if c in topics_few_facets else -1 for c in model.doc_topic])\n",
    "axs = umap.plot.points(umap_model_2d, labels=labels, background='black',\n",
    "                       height=1200, width=1200, show_legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document pairs sampling for fine -tuned facet detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_per_topic = 0.05\n",
    "quantiles_sim = [0.2, 0.4, 0.6, 0.8, 0.99]\n",
    "n_to_sample = (pct_per_topic * model.topic_sizes).round()\n",
    "digits_q = list(range(len(quantiles_sim)))\n",
    "\n",
    "dict_samples = helpers.sample_doc_pairs(model, pct_per_topic, quantiles_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20201127_cmv_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
